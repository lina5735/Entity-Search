{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53b884ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import stats\n",
    "from scipy import linalg, mat, dot\n",
    "from collections import Counter\n",
    "import string\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from ast import literal_eval\n",
    "\n",
    "from file_operations import get_all_files, process_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdb1bdf-7500-4915-8bb1-5ec3dc61c67b",
   "metadata": {},
   "source": [
    "## Store Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9106914",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../data/cnn_dailymail/data\"\n",
    "daily_path, cnn_path = \"/dailymail/stories/\", \"/cnn/stories/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f47e972-d0ce-468d-ac0f-0419b049fe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    with open(root+daily_path+file_path, 'r') as file:\n",
    "        \n",
    "        content = file.read()\n",
    "        content = content.split(\"@highlight\")[0]\n",
    "        \n",
    "        # Tokenize the text\n",
    "        result = process_token(content)\n",
    "\n",
    "        return file_path, result\n",
    "\n",
    "def token_all_files(path):\n",
    "    file_paths = get_all_files(path)\n",
    "    id_list=[]\n",
    "    content_list=[]\n",
    "    for path in file_paths:\n",
    "        file_path,content=read_file(path)\n",
    "        id_list.append(file_path)\n",
    "        content_list.append(content)\n",
    "        \n",
    "    return pd.DataFrame({\"id\":id_list,'content': content_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37855168",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_cnn=token_all_files(root+cnn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d919b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>638ba1352bdf405a8f5bd681d7fe5c928686afff.story</td>\n",
       "      <td>[start, big, week, higgs, boson, soughtafter, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f9f9601180ab3278165d936821e8f145659997f3.story</td>\n",
       "      <td>[cnn, george, zimmerman, acquitted, florida, j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80ec0efb252ec4470aee44482d1e196111b5780b.story</td>\n",
       "      <td>[cnn, zlatan, ibrahimovic, scored, third, goal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8435150be66ea9792999dfc233cc690f9c2fe2d0.story</td>\n",
       "      <td>[cnn, nobel, laureate, norman, e, borlaug, agr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1444cf4d1832507a29a98529c2cd1a41f0154b52.story</td>\n",
       "      <td>[cnn, louisiana, gov, bobby, jindal, monday, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92573</th>\n",
       "      <td>d9699dc87c898b466b112fea8b48980e9df6e08d.story</td>\n",
       "      <td>[weimar, germany, cnn, long, narrow, road, win...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92574</th>\n",
       "      <td>9db26e940aa59bda5bf4244c32b30fdd7d07c357.story</td>\n",
       "      <td>[james, theodorou, reflects, mistake, past, jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92575</th>\n",
       "      <td>432986f7670e5fa46f4c2d46e696f8957d0fb8de.story</td>\n",
       "      <td>[cnn, going, green, green, light, business, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92576</th>\n",
       "      <td>4ecc129fd7231a641a2b545ecb5f667e94df6b66.story</td>\n",
       "      <td>[prague, czech, republic, cnn, fireworks, rock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92577</th>\n",
       "      <td>818fcac70cccea5a042a0f44eef23cd6c3e415b3.story</td>\n",
       "      <td>[cnn, australian, authority, declared, several...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92578 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   id  \\\n",
       "0      638ba1352bdf405a8f5bd681d7fe5c928686afff.story   \n",
       "1      f9f9601180ab3278165d936821e8f145659997f3.story   \n",
       "2      80ec0efb252ec4470aee44482d1e196111b5780b.story   \n",
       "3      8435150be66ea9792999dfc233cc690f9c2fe2d0.story   \n",
       "4      1444cf4d1832507a29a98529c2cd1a41f0154b52.story   \n",
       "...                                               ...   \n",
       "92573  d9699dc87c898b466b112fea8b48980e9df6e08d.story   \n",
       "92574  9db26e940aa59bda5bf4244c32b30fdd7d07c357.story   \n",
       "92575  432986f7670e5fa46f4c2d46e696f8957d0fb8de.story   \n",
       "92576  4ecc129fd7231a641a2b545ecb5f667e94df6b66.story   \n",
       "92577  818fcac70cccea5a042a0f44eef23cd6c3e415b3.story   \n",
       "\n",
       "                                                 content  \n",
       "0      [start, big, week, higgs, boson, soughtafter, ...  \n",
       "1      [cnn, george, zimmerman, acquitted, florida, j...  \n",
       "2      [cnn, zlatan, ibrahimovic, scored, third, goal...  \n",
       "3      [cnn, nobel, laureate, norman, e, borlaug, agr...  \n",
       "4      [cnn, louisiana, gov, bobby, jindal, monday, s...  \n",
       "...                                                  ...  \n",
       "92573  [weimar, germany, cnn, long, narrow, road, win...  \n",
       "92574  [james, theodorou, reflects, mistake, past, jo...  \n",
       "92575  [cnn, going, green, green, light, business, co...  \n",
       "92576  [prague, czech, republic, cnn, fireworks, rock...  \n",
       "92577  [cnn, australian, authority, declared, several...  \n",
       "\n",
       "[92578 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2430dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_dailymail=token_all_files(root+daily_path)\n",
    "result_df_dailymail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dd90a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=pd.concat([result_df_cnn, result_df_dailymail], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36f5fe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.iloc[:int(0.5*len(result_df)),:].to_csv('/Users/daiqiaochu/Desktop/ISE540/project/half_result1.csv', index=False)\n",
    "result_df.iloc[int(0.5*len(result_df)):,:].to_csv('/Users/daiqiaochu/Desktop/ISE540/project/half_result2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749773ba-e518-4b79-987d-b7240cd0eaae",
   "metadata": {},
   "source": [
    "#### entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df769951-9206-496b-8bbf-667d7070d98f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d47af8f",
   "metadata": {},
   "source": [
    "## Compute TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f404e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../data/tf_idf/full_text/\"\n",
    "half_result=pd.read_csv(root+'half_result2.csv')\n",
    "with open(root+'idf.json', 'r') as file:\n",
    "    idf_file = json.load(file)\n",
    "with open(root+'vocabulary.json', 'r') as file:\n",
    "    vocabulary_file = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd0b3ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=half_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f835e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dic={}\n",
    "for i in range(len(result_df)):\n",
    "    final_dic[result_df.iloc[i,0]]=literal_eval(result_df.iloc[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a10762c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from collections import Counter\n",
    "import concurrent.futures\n",
    "import traceback\n",
    "\n",
    "def calculate_TF(Seg_Docs, ID):\n",
    "    if ID in Seg_Docs:\n",
    "        term_counts=Counter(Seg_Docs[ID])\n",
    "        TF_dic={term: count for term, count in term_counts.items()}\n",
    "        return TF_dic\n",
    "    else:\n",
    "        print('Error: This key does not exist in the document')\n",
    "        \n",
    "def calculate_TFIDF(ID, Vocabulary, IDF_list):\n",
    "    global final_dic\n",
    "    Seg_Docs=final_dic\n",
    "    non_zero_values = []\n",
    "    non_zero_indices=[]\n",
    "    TF_list = calculate_TF(Seg_Docs, ID)\n",
    "    i=0\n",
    "    for word in Vocabulary:\n",
    "        if word in TF_list:\n",
    "            non_zero_values.append(IDF_list[word] * TF_list[word])\n",
    "            non_zero_indices.append(i)\n",
    "            \n",
    "        i+=1\n",
    "    return non_zero_values,non_zero_indices\n",
    "\n",
    "def process_and_save_row(ID):\n",
    "    global vocabulary_file\n",
    "    global idf_file\n",
    "    Vocabulary=vocabulary_file\n",
    "    nonzero_values, nonzero_positions= calculate_TFIDF(ID, Vocabulary, idf_file)\n",
    "    row_values=[ID,nonzero_values,nonzero_positions]\n",
    "    with open(root+'tfidf_result2.csv', 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow([value for value in row_values])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a20bab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(final_dic.keys())\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    executor.map(process_and_save_row, keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be6d40-de99-43a2-98ca-4abebd601833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Create a two-column dataframe\n",
    "df = pd.DataFrame({\n",
    "    'values': [1, 2, 3, 1],\n",
    "    'positions': [0, 1, 2, 8]\n",
    "})\n",
    "\n",
    "# Convert the dataframe back to a sparse matrix\n",
    "original_matrix = csr_matrix((df['values'], df['positions'], [0, len(df)]), shape=(1, 11))\n",
    "\n",
    "print(\"Original Matrix:\")\n",
    "print(original_matrix.toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
