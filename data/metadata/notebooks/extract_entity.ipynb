{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e24ab00",
   "metadata": {},
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f159b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "import pandas as pd\n",
    "import calendar\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a87b48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load language model\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "folder_path = \"/Users/irisgong/Desktop/ISE540 Text Analytics/project/data/label/label_story\"\n",
    "\n",
    "retrieved_documents = {}\n",
    "\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".story\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            document = file.read()\n",
    "            \n",
    "            people = set()\n",
    "            organizations = set()\n",
    "            locations = set()\n",
    "            dates = set()\n",
    "            doc = nlp(document)\n",
    "            \n",
    "            \n",
    "            for ent in doc.ents:\n",
    "                text = re.sub(r\"'s\\b\", '', ent.text)\n",
    "                text = text.replace('\\n', '')\n",
    "                text = text.replace('\\xa0', '')\n",
    "                if ent.label_ == \"PERSON\":\n",
    "                    people.add(text)\n",
    "                elif ent.label_ == \"ORG\":\n",
    "                    organizations.add(text)\n",
    "                elif ent.label_ in [\"LOC\", \"GPE\"]:\n",
    "                    locations.add(text)\n",
    "                elif ent.label_ == \"DATE\":\n",
    "                    dates.add(text)\n",
    "            \n",
    "\n",
    "            result = {\n",
    "                'People': people,\n",
    "                'Organizations': organizations,\n",
    "                'Locations': locations,\n",
    "                'Dates': dates\n",
    "            }\n",
    "\n",
    "            retrieved_documents[filename] = result\n",
    "            \n",
    "            \n",
    "retrieved_documents = dict(sorted(retrieved_documents.items(), key=lambda item: item[0]))\n",
    "\n",
    "\n",
    "# Delete date tag\n",
    "unwanted_dates = {\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\",}\n",
    "\n",
    "for filename, result in retrieved_documents.items():\n",
    "    result['Dates'] -= unwanted_dates\n",
    "    \n",
    "\n",
    "# Delete phrase\n",
    "unwanted_phrases = {\"year\", \"month\", \"week\", \"day\", \"old\", \"annual\", \"season\", \"daily\", \"decade\", \"decades\", \"this\", \"next\", \"last\", \"more\"}\n",
    "\n",
    "for filename, result in retrieved_documents.items():\n",
    "    result['Dates'] = {date for date in result['Dates'] if not any(word in date.lower() for word in unwanted_phrases)}\n",
    "    \n",
    "    \n",
    "# Except date tags containing only one month word\n",
    "months_to_remove = [month.lower() for month in calendar.month_name[1:]]\n",
    "\n",
    "for filename, result in retrieved_documents.items():\n",
    "    result['Dates'] = {date for date in result['Dates'] if not (date.lower() in months_to_remove and len(date.split()) == 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eacad6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "\n",
    "excel_path = \"/Users/irisgong/Desktop/ISE540 Text Analytics/project/data/label/label.xlsx\"\n",
    "df = pd.read_excel(excel_path)\n",
    "\n",
    "ground_truth = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    file_id = row['id']\n",
    "    \n",
    "    # If there is no space after the comma, add the space\n",
    "    people_raw = str(row['person']) if pd.notna(row['person']) else \"\"\n",
    "    people_raw = ', '.join([p.strip() for p in people_raw.split(',')])\n",
    "    people = set([p.strip() for p in people_raw.split(', ') if p.strip()])\n",
    "    \n",
    "    organizations_raw = str(row['organization']) if pd.notna(row['organization']) else \"\"\n",
    "    organizations_raw = ', '.join([o.strip() for o in organizations_raw.split(',')])\n",
    "    organizations = set([o.strip() for o in organizations_raw.split(', ') if o.strip()])\n",
    "    \n",
    "    locations_raw = str(row['location']) if pd.notna(row['location']) else \"\"\n",
    "    locations_raw = ', '.join([l.strip() for l in locations_raw.split(',')])\n",
    "    locations = set([l.strip() for l in locations_raw.split(', ') if l.strip()])\n",
    "\n",
    "    dates_raw = str(row['date']) if pd.notna(row['date']) else \"\"\n",
    "    dates_raw = ', '.join([d.strip() for d in dates_raw.split(',')])\n",
    "    dates = set([d.strip() for d in dates_raw.split(', ') if d.strip()])\n",
    "\n",
    "\n",
    "    result_1 = {\n",
    "        'People': people,\n",
    "        'Organizations': organizations,\n",
    "        'Locations': locations,\n",
    "        'Dates': dates\n",
    "    }\n",
    "\n",
    "    ground_truth[file_id] = result_1\n",
    "\n",
    "\n",
    "ground_truth = dict(sorted(ground_truth.items()))\n",
    "\n",
    "\n",
    "# Delete date tag\n",
    "unwanted_dates = {\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\",}\n",
    "\n",
    "for filename, result in ground_truth.items():\n",
    "    result['Dates'] -= unwanted_dates\n",
    "    \n",
    "\n",
    "# Delete phrase\n",
    "unwanted_phrases = {\"year\", \"month\", \"week\", \"day\", \"old\", \"annual\", \"season\", \"daily\", \"decade\", \"decades\", \"this\", \"next\", \"last\", \"more\"}\n",
    "\n",
    "for filename, result in ground_truth.items():\n",
    "    result['Dates'] = {date for date in result['Dates'] if not any(word in date.lower() for word in unwanted_phrases)}\n",
    "    \n",
    "    \n",
    "# Except date tags containing only one month word\n",
    "months_to_remove = [month.lower() for month in calendar.month_name[1:]]\n",
    "\n",
    "for filename, result in ground_truth.items():\n",
    "    result['Dates'] = {date for date in result['Dates'] if not (date.lower() in months_to_remove and len(date.split()) == 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef5b310b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame已成功导出到 /Users/irisgong/Desktop/ISE540 Text Analytics/project/retrieved.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Export to Excel file\n",
    "df = pd.DataFrame(retrieved_documents)\n",
    "df_transposed = df.transpose()\n",
    "\n",
    "excel_path = '/Users/irisgong/Desktop/ISE540 Text Analytics/project/retrieved.xlsx'\n",
    "df_transposed.to_excel(excel_path, index=False)\n",
    "\n",
    "\n",
    "print(f'DataFrame successfully exported to {excel_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6f378f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame已成功导出到 /Users/irisgong/Desktop/ISE540 Text Analytics/project/ground_truth.xlsx\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "df2 = pd.DataFrame(ground_truth)\n",
    "df2_transposed = df2.transpose()\n",
    "\n",
    "excel_path = '/Users/irisgong/Desktop/ISE540 Text Analytics/project/ground_truth.xlsx'\n",
    "df2_transposed.to_excel(excel_path, index=False)\n",
    "\n",
    "\n",
    "print(f'DataFrame successfully exported to {excel_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b65e6336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_ID</th>\n",
       "      <th>Precision_Person</th>\n",
       "      <th>Recall_Person</th>\n",
       "      <th>F1_Person</th>\n",
       "      <th>Precision_Org</th>\n",
       "      <th>Recall_Org</th>\n",
       "      <th>F1_Org</th>\n",
       "      <th>Precision_Loc</th>\n",
       "      <th>Recall_Loc</th>\n",
       "      <th>F1_Loc</th>\n",
       "      <th>Precision_Date</th>\n",
       "      <th>Recall_Date</th>\n",
       "      <th>F1_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000800d9058217f6509d7e63ad475e2de0da611.story</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001d4ce3598e37f20a47fe609736f72e5d73467.story</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002067d13d3ca304e0bc98d04dde85d4091c55e.story</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000219931d2c3aae55dc2acdc5f690d0c112ab17.story</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00022dbfa44ccdb94c1dc06938047e258076cf75.story</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>ff6bb1e8a47fdd6c32f14201b7aa50dd7720a9ca.story</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>ff95cbf06bc9e4b2b0c4bb7b46794e63cacaa834.story</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>ffcbb4742e7df96316bda9385d8ec14078aa5b3f.story</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>ffd480659edff188a04fbd2114b0f63113669407.story</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>fffb9fbf64cc936c10ecef14b684ac67b6b6b9e7.story</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            File_ID  Precision_Person  \\\n",
       "0    0000800d9058217f6509d7e63ad475e2de0da611.story          0.900000   \n",
       "1    0001d4ce3598e37f20a47fe609736f72e5d73467.story          0.583333   \n",
       "2    0002067d13d3ca304e0bc98d04dde85d4091c55e.story          0.500000   \n",
       "3    000219931d2c3aae55dc2acdc5f690d0c112ab17.story          0.538462   \n",
       "4    00022dbfa44ccdb94c1dc06938047e258076cf75.story          0.666667   \n",
       "..                                              ...               ...   \n",
       "245  ff6bb1e8a47fdd6c32f14201b7aa50dd7720a9ca.story          0.700000   \n",
       "246  ff95cbf06bc9e4b2b0c4bb7b46794e63cacaa834.story          0.500000   \n",
       "247  ffcbb4742e7df96316bda9385d8ec14078aa5b3f.story          0.764706   \n",
       "248  ffd480659edff188a04fbd2114b0f63113669407.story          1.000000   \n",
       "249  fffb9fbf64cc936c10ecef14b684ac67b6b6b9e7.story          0.666667   \n",
       "\n",
       "     Recall_Person  F1_Person  Precision_Org  Recall_Org    F1_Org  \\\n",
       "0         0.692308   0.782609       0.000000    0.000000         0   \n",
       "1         0.700000   0.636364       0.090909    0.200000     0.125   \n",
       "2         0.571429   0.533333       0.400000    1.000000  0.571429   \n",
       "3         0.777778   0.636364       0.333333    0.333333  0.333333   \n",
       "4         1.000000   0.800000       0.400000    1.000000  0.571429   \n",
       "..             ...        ...            ...         ...       ...   \n",
       "245       0.700000   0.700000       0.555556    0.714286     0.625   \n",
       "246       1.000000   0.666667       0.833333    0.909091  0.869565   \n",
       "247       0.866667   0.812500       0.500000    0.500000       0.5   \n",
       "248       1.000000   1.000000       0.000000    0.000000         0   \n",
       "249       0.500000   0.571429       0.705882    0.923077       0.8   \n",
       "\n",
       "     Precision_Loc  Recall_Loc    F1_Loc  Precision_Date Recall_Date   F1_Date  \n",
       "0         0.777778    0.875000  0.823529        0.000000           0         0  \n",
       "1         0.555556    0.833333  0.666667        0.000000           0         0  \n",
       "2         0.400000    0.666667  0.500000        0.666667         0.8  0.727273  \n",
       "3         0.600000    1.000000  0.750000        0.250000         0.5  0.333333  \n",
       "4         0.200000    1.000000  0.333333        0.000000         0.0         0  \n",
       "..             ...         ...       ...             ...         ...       ...  \n",
       "245       0.400000    1.000000  0.571429        0.230769    0.428571       0.3  \n",
       "246       0.222222    1.000000  0.363636        1.000000         1.0       1.0  \n",
       "247       0.000000    0.000000  0.000000        0.157895    0.142857      0.15  \n",
       "248       0.600000    1.000000  0.750000        0.000000           0         0  \n",
       "249       0.219512    0.750000  0.339623        0.500000         1.0  0.666667  \n",
       "\n",
       "[250 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_precision_recall_f1_for_file(ground_truth, retrieved_documents, file_id, label):\n",
    "    ground_truth_labels = set(ground_truth[file_id].get(label, []))\n",
    "    retrieved_labels = set(retrieved_documents.get(file_id, {}).get(label, []))\n",
    "\n",
    "    true_positives = len(ground_truth_labels & retrieved_labels)\n",
    "    false_positives = len(retrieved_labels - ground_truth_labels)\n",
    "    false_negatives = len(ground_truth_labels - retrieved_labels)\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) != 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) != 0 else 0\n",
    "    F1_measure = (2 * precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "    return precision, recall, F1_measure\n",
    "\n",
    "\n",
    "result_df = pd.DataFrame(columns=[\n",
    "    'File_ID',\n",
    "    'Precision_Person', 'Recall_Person', 'F1_Person',\n",
    "    'Precision_Org', 'Recall_Org', 'F1_Org',\n",
    "    'Precision_Loc', 'Recall_Loc', 'F1_Loc',\n",
    "    'Precision_Date', 'Recall_Date', 'F1_Date'\n",
    "])\n",
    "\n",
    "\n",
    "for file_id in ground_truth.keys():\n",
    "    # Calculate precision and recall\n",
    "    precision_person, recall_person, f1_person = calculate_precision_recall_f1_for_file(ground_truth, retrieved_documents, file_id, 'People')\n",
    "    precision_org, recall_org, f1_org = calculate_precision_recall_f1_for_file(ground_truth, retrieved_documents, file_id, 'Organizations')\n",
    "    precision_loc, recall_loc, f1_loc = calculate_precision_recall_f1_for_file(ground_truth, retrieved_documents, file_id, 'Locations')\n",
    "    precision_date, recall_date, f1_date = calculate_precision_recall_f1_for_file(ground_truth, retrieved_documents, file_id, 'Dates')\n",
    "\n",
    "    # Append the results to the DataFrame\n",
    "    result_df = pd.concat([result_df, pd.DataFrame({\n",
    "        'File_ID': [file_id],\n",
    "        'Precision_Person': [precision_person],\n",
    "        'Recall_Person': [recall_person],\n",
    "        'F1_Person': [f1_person],\n",
    "        'Precision_Org': [precision_org],\n",
    "        'Recall_Org': [recall_org],\n",
    "        'F1_Org': [f1_org],\n",
    "        'Precision_Loc': [precision_loc],\n",
    "        'Recall_Loc': [recall_loc],\n",
    "        'F1_Loc': [f1_loc],\n",
    "        'Precision_Date': [precision_date],\n",
    "        'Recall_Date': [recall_date],\n",
    "        'F1_Date': [f1_date],\n",
    "    })], ignore_index=True)\n",
    "\n",
    "    \n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a7d73cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame已成功导出到 /Users/irisgong/Desktop/ISE540 Text Analytics/project/spaCy_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Export to Excel file\n",
    "excel_path = '/Users/irisgong/Desktop/ISE540 Text Analytics/project/spaCy_output.xlsx'\n",
    "result_df.to_excel(excel_path, index=False)\n",
    "\n",
    "print(f'DataFrame successfully exported to {excel_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a1383f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy\n",
      "Precision_Person : 0.6397048998184143\n",
      "Recall_Person : 0.8271890973639272\n",
      "F1_Person : 0.7031142158508964\n",
      "Precision_Org : 0.4033081500852089\n",
      "Recall_Org : 0.523700027755465\n",
      "F1_Org : 0.4278620331323703\n",
      "Precision_Loc : 0.4807975915440015\n",
      "Recall_Loc : 0.6763770567001056\n",
      "F1_Loc : 0.5332335667494131\n",
      "Precision_Date : 0.3504062228220123\n",
      "Recall_Date : 0.47554742664742666\n",
      "F1_Date : 0.38467598637583833\n"
     ]
    }
   ],
   "source": [
    "print(\"SpaCy\")\n",
    "for column in result_df.columns[1:13]:\n",
    "    print(column, \":\", result_df[column].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613626db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "440370ae",
   "metadata": {},
   "source": [
    "用上述模型跑完30w个文档，储存extracted entity到单独的文档(csv:id, entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40147518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract CNN - date\n",
    "folder_path = \"/Users/irisgong/Desktop/ISE540 Text Analytics/project/data/原数据/cnn/stories\"\n",
    "\n",
    "retrieved_documents_cnn = {}\n",
    "\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".story\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        \n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            document = file.read()\n",
    "            \n",
    "            dates = set()\n",
    "            doc = nlp(document)\n",
    "            file_id = filename.split('.story')[0]\n",
    "            \n",
    "            for ent in doc.ents:\n",
    "                text = re.sub(r\"'s\\b\", '', ent.text)\n",
    "                text = text.replace('\\n', '')\n",
    "                text = text.replace('\\xa0', '')\n",
    "                if ent.label_ == \"DATE\":\n",
    "                    dates.add(text)\n",
    "            \n",
    "\n",
    "            result = {\n",
    "                'ID': file_id\n",
    "                'Dates': dates\n",
    "            }\n",
    "            \n",
    "\n",
    "            retrieved_documents_cnn[filename] = result\n",
    "            \n",
    "            \n",
    "retrieved_documents_cnn = dict(sorted(retrieved_documents_cnn.items(), key=lambda item: item[0]))\n",
    "\n",
    "\n",
    "# Delete date tag\n",
    "unwanted_dates = {\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\",}\n",
    "\n",
    "for filename, result in retrieved_documents_cnn.items():\n",
    "    result['Dates'] -= unwanted_dates\n",
    "    \n",
    "\n",
    "# Delete phrase\n",
    "unwanted_phrases = {\"year\", \"month\", \"week\", \"day\", \"old\", \"annual\", \"season\", \"daily\", \"decade\", \"decades\", \"this\", \"next\", \"last\", \"more\"}\n",
    "\n",
    "for filename, result in retrieved_documents_cnn.items():\n",
    "    result['Dates'] = {date for date in result['Dates'] if not any(word in date.lower() for word in unwanted_phrases)}\n",
    "\n",
    "\n",
    "# Except date tags containing only one month word\n",
    "months_to_remove = [month.lower() for month in calendar.month_name[1:]]\n",
    "\n",
    "for filename, result in retrieved_documents_cnn.items():\n",
    "    result['Dates'] = {date for date in result['Dates'] if not (date.lower() in months_to_remove and len(date.split()) == 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e0afa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame已成功导出到 /Users/irisgong/Desktop/ISE540 Text Analytics/project/retrieved_date_cnn.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Export to Excel file\n",
    "df_cnn = pd.DataFrame(retrieved_documents_cnn)\n",
    "df_cnn_transposed = df_cnn.transpose()\n",
    "\n",
    "excel_path = '/Users/irisgong/Desktop/ISE540 Text Analytics/project/retrieved_date_cnn.xlsx'\n",
    "df_cnn_transposed.to_excel(excel_path, index=False)\n",
    "\n",
    "\n",
    "print(f'DataFrame successfully exported to {excel_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ab3fc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Daily Mail - date\n",
    "folder_path = \"/Users/irisgong/Desktop/ISE540 Text Analytics/project/data/原数据/dailymail/stories\"\n",
    "\n",
    "retrieved_documents_dm = {}\n",
    "\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".story\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "\n",
    "  \n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            document = file.read()\n",
    "            \n",
    "            dates = set()\n",
    "            doc = nlp(document)\n",
    "            file_id = filename.split('.story')[0]\n",
    "            \n",
    "            for ent in doc.ents:\n",
    "                text = re.sub(r\"'s\\b\", '', ent.text)\n",
    "                text = text.replace('\\n', '')\n",
    "                text = text.replace('\\xa0', '')\n",
    "                if ent.label_ == \"DATE\":\n",
    "                    dates.add(text)\n",
    "            \n",
    "            \n",
    "            result = {\n",
    "                'ID': file_id\n",
    "                'Dates': dates\n",
    "            }\n",
    "            \n",
    "         \n",
    "            retrieved_documents_dm[filename] = result\n",
    "            \n",
    "            \n",
    "retrieved_documents_dm = dict(sorted(retrieved_documents_dm.items(), key=lambda item: item[0]))\n",
    "\n",
    "\n",
    "# Delete date tag\n",
    "unwanted_dates = {\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\",}\n",
    "\n",
    "for filename, result in retrieved_documents_dm.items():\n",
    "    result['Dates'] -= unwanted_dates\n",
    "    \n",
    "\n",
    "# Delete phrase\n",
    "unwanted_phrases = {\"year\", \"month\", \"week\", \"day\", \"old\", \"annual\", \"season\", \"daily\", \"decade\", \"decades\", \"this\", \"next\", \"last\", \"more\"}\n",
    "\n",
    "for filename, result in retrieved_documents_dm.items():\n",
    "    result['Dates'] = {date for date in result['Dates'] if not any(word in date.lower() for word in unwanted_phrases)}\n",
    "\n",
    "\n",
    "# Except date tags containing only one month word\n",
    "months_to_remove = [month.lower() for month in calendar.month_name[1:]]\n",
    "\n",
    "for filename, result in retrieved_documents_dm.items():\n",
    "    result['Dates'] = {date for date in result['Dates'] if not (date.lower() in months_to_remove and len(date.split()) == 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3a7498e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame已成功导出到 /Users/irisgong/Desktop/ISE540 Text Analytics/project/retrieved_date_dm.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Export to Excel file\n",
    "df_dm = pd.DataFrame(retrieved_documents_dm)\n",
    "df_dm_transposed = df_dm.transpose()\n",
    "\n",
    "excel_path = '/Users/irisgong/Desktop/ISE540 Text Analytics/project/retrieved_date_dm.xlsx'\n",
    "df_dm_transposed.to_excel(excel_path, index=False)\n",
    "\n",
    "\n",
    "print(f'DataFrame已成功导出到 {excel_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66285c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Daily Mail - people&org\n",
    "folder_path = \"/Users/irisgong/Desktop/ISE540 Text Analytics/project/data/原数据/dailymail/stories\"\n",
    "\n",
    "retrieved_documents_dm = {}\n",
    "\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".story\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "\n",
    "        \n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            document = file.read()\n",
    "            \n",
    "            people = set()\n",
    "            organizations = set()\n",
    "            doc = nlp(document)\n",
    "            file_id = filename.split('.story')[0]\n",
    "            \n",
    "            for ent in doc.ents:\n",
    "                text = re.sub(r\"'s\\b\", '', ent.text)\n",
    "                text = text.replace('\\n', '')\n",
    "                text = text.replace('\\xa0', '')\n",
    "                if ent.label_ == \"PERSON\":\n",
    "                    people.add(text)\n",
    "                elif ent.label_ == \"ORG\":\n",
    "                    organizations.add(text)\n",
    "            \n",
    "           \n",
    "            result = {\n",
    "                'ID': file_id,\n",
    "                'People': people,\n",
    "                'Organizations': organizations\n",
    "            }\n",
    "            \n",
    "            \n",
    "            retrieved_documents_dm[filename] = result\n",
    "            \n",
    "            \n",
    "retrieved_documents_dm = dict(sorted(retrieved_documents_dm.items(), key=lambda item: item[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f9e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Excel 文件\n",
    "df_dm = pd.DataFrame(retrieved_documents_dm)\n",
    "df_dm_transposed = df_dm.transpose()\n",
    "\n",
    "excel_path = '/Users/irisgong/Desktop/ISE540 Text Analytics/project/retrieved_people&org_dm.xlsx'\n",
    "df_dm_transposed.to_excel(excel_path, index=False)\n",
    "\n",
    "\n",
    "print(f'DataFrame已成功导出到 {excel_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cee4a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/irisgong/Desktop/ISE540 Text Analytics/project/data/原数据/cnn/stories'\n",
    "\n",
    "retrieved_documents_cnn_id = {}\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    id = filename.split('.story')[0]\n",
    "    result = {'ID': filename\n",
    "#                 'People': people,\n",
    "#                 'Organizations': organizations,\n",
    "            }\n",
    "\n",
    "#             # Store the result in the main dictionary\n",
    "    retrieved_documents_cnn_id[filename] = result\n",
    "\n",
    "# Sort retrieved documents by filename\n",
    "retrieved_documents_cnn_id = dict(sorted(retrieved_documents_cnn_id.items(), key=lambda item: item[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af7b23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
